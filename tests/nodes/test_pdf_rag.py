"""Test PDF RAG extraction node independently with real PDF from DGCMEF."""

import sys
sys.path.insert(0, '/app/src')

import json
import tempfile
import requests
from pathlib import Path
from datetime import datetime

from tenderai_bf.agents.nodes.parse_pdf_rag import (
    extract_text_from_pdf,
    split_into_chunks,
    parse_pdf_with_rag
)

# Real PDF URL from DGCMEF
PDF_URL = "https://dgcmef.gov.bf/sites/default/files/2025-11/Quotidien%20N%C2%B04269.pdf"

# Output JSON file path (logs directory is mounted and confirmed writable)
OUTPUT_JSON = "/app/logs/test_extracted_tenders.json"


def clear_json_file():
    """Clear the output JSON file before starting extraction."""
    print(f"\nğŸ—‘ï¸  Nettoyage du fichier JSON: {OUTPUT_JSON}")
    try:
        with open(OUTPUT_JSON, 'w') as f:
            json.dump([], f)
        print("âœ… Fichier JSON vidÃ©")
    except Exception as e:
        print(f"âš ï¸  Erreur lors du nettoyage: {e}")


def save_tenders_to_json(tenders: list, test_name: str):
    """Save extracted tenders to JSON file.
    
    Args:
        tenders: List of extracted tender dictionaries
        test_name: Name of the test that extracted the tenders
    """
    if not tenders:
        print("âš ï¸  Aucun tender Ã  sauvegarder")
        return
    
    try:
        # Read existing data
        try:
            with open(OUTPUT_JSON, 'r') as f:
                existing_data = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            existing_data = []
        
        # Add metadata to each tender
        timestamp = datetime.now().isoformat()
        for tender in tenders:
            tender['_test_name'] = test_name
            tender['_extracted_at'] = timestamp
        
        # Append new tenders
        existing_data.extend(tenders)
        
        # Save back to file
        with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ Tenders sauvegardÃ©s dans: {OUTPUT_JSON}")
        print(f"   Nombre ajoutÃ©: {len(tenders)}")
        print(f"   Total dans le fichier: {len(existing_data)}")
        
    except Exception as e:
        print(f"âŒ Erreur lors de la sauvegarde: {e}")


def download_pdf(url: str) -> str:
    """Download PDF from URL and save to temporary file.
    
    Args:
        url: URL of the PDF to download
        
    Returns:
        Path to the downloaded PDF file
    """
    print(f"\nğŸŒ TÃ©lÃ©chargement du PDF depuis:")
    print(f"   {url}")
    
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        # Create temporary file
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pdf')
        temp_file.write(response.content)
        temp_file.close()
        
        file_size_mb = len(response.content) / (1024 * 1024)
        print(f"âœ… PDF tÃ©lÃ©chargÃ©: {temp_file.name}")
        print(f"   Taille: {file_size_mb:.2f} MB")
        
        return temp_file.name
        
    except Exception as e:
        print(f"âŒ Erreur lors du tÃ©lÃ©chargement: {e}")
        raise


def test_extract_text():
    """Test text extraction from real DGCMEF PDF."""
    
    print("\n" + "=" * 80)
    print("TEST 1: Extraction de texte depuis PDF rÃ©el (DGCMEF)")
    print("=" * 80)
    
    # Download PDF
    pdf_path = download_pdf(PDF_URL)
    
    try:
        # Extract text
        print("\nğŸ”„ Extraction du texte avec Docling...")
        text = extract_text_from_pdf(pdf_path)
        
        print("\nâœ… Texte extrait avec succÃ¨s!")
        print(f"   Longueur: {len(text)} caractÃ¨res")
        print(f"   Mots: ~{len(text.split())} mots")
        print(f"   Lignes: ~{len(text.splitlines())} lignes")
        
        print("\nğŸ“„ Extrait (1000 premiers caractÃ¨res):")
        print("-" * 80)
        print(text[:1000])
        print("-" * 80)
        
        # Check for tender-related keywords
        keywords = ['appel', 'offres', 'marchÃ©', 'consultation', 'avis']
        found_keywords = [kw for kw in keywords if kw.lower() in text.lower()]
        print(f"\nğŸ” Mots-clÃ©s trouvÃ©s: {', '.join(found_keywords) if found_keywords else 'aucun'}")
        
        return text
        
    finally:
        # Cleanup
        Path(pdf_path).unlink(missing_ok=True)


def test_chunk_splitting():
    """Test text chunking with RecursiveCharacterTextSplitter on real PDF."""
    
    print("\n" + "=" * 80)
    print("TEST 2: DÃ©coupage en chunks (RAG) - PDF rÃ©el")
    print("=" * 80)
    
    # Download PDF
    pdf_path = download_pdf(PDF_URL)
    
    try:
        # Extract text
        text = extract_text_from_pdf(pdf_path)
        
        print(f"\nğŸ“„ Texte extrait: {len(text)} caractÃ¨res")
        
        # Split into chunks
        print("\nğŸ”„ DÃ©coupage en chunks...")
        chunks = split_into_chunks(text)
        
        print("\nâœ… DÃ©coupage terminÃ©!")
        print(f"   Nombre de chunks: {len(chunks)}")
        print(f"   Taille moyenne: {sum(len(c) for c in chunks) / len(chunks):.0f} caractÃ¨res")
        print(f"   Chunk min: {min(len(c) for c in chunks)} caractÃ¨res")
        print(f"   Chunk max: {max(len(c) for c in chunks)} caractÃ¨res")
        
        print("\nğŸ“‹ AperÃ§u des chunks:")
        for i, chunk in enumerate(chunks[:3], 1):  # Show first 3 chunks
            print(f"\n--- Chunk {i} ({len(chunk)} chars) ---")
            print(chunk[:300] + "..." if len(chunk) > 300 else chunk)
        
        if len(chunks) > 3:
            print(f"\n... et {len(chunks) - 3} autres chunks")
        
        return chunks
        
    finally:
        Path(pdf_path).unlink(missing_ok=True)


def test_full_rag_extraction():
    """Test complete RAG-based extraction pipeline on real DGCMEF PDF."""
    
    print("\n" + "=" * 80)
    print("TEST 3: Extraction complÃ¨te avec RAG + LLM - PDF rÃ©el DGCMEF")
    print("=" * 80)
    
    # Download PDF
    pdf_path = download_pdf(PDF_URL)
    
    try:
        print(f"\nğŸ“„ PDF: {pdf_path}")
        print("\nğŸ”„ Extraction RAG en cours...")
        print("   (Indexation vectorielle + recherche sÃ©mantique + LLM)")
        print("   âš ï¸  Cela peut prendre plusieurs minutes...")
        
        # Run full RAG extraction
        tenders = parse_pdf_with_rag(
            pdf_path=pdf_path,
            source_name="DGCMEF_QUOTIDIEN_4269",
            filename="Quotidien NÂ°4269.pdf",
            metadata={"source": "dgcmef", "type": "quotidien"},
            use_llm=True,
            use_direct_extraction=False  # Use RAG, not direct extraction
        )
        
        print("\nâœ… Extraction terminÃ©e!")
        print(f"   Tenders extraits: {len(tenders)}")
        
        # Save to JSON file
        save_tenders_to_json(tenders, "RAG_extraction")
        
        if tenders:
            print("\nğŸ“‹ Tenders extraits du Quotidien NÂ°4269:")
            print("=" * 80)
            for i, tender in enumerate(tenders, 1):
                print(f"\nğŸ¯ Tender {i}/{len(tenders)}:")
                print(f"   EntitÃ©: {tender.get('entity', 'N/A')}")
                print(f"   RÃ©fÃ©rence: {tender.get('reference', 'N/A')}")
                print(f"   CatÃ©gorie: {tender.get('category', 'N/A')}")
                print(f"   Budget: {tender.get('budget', 'N/A')}")
                print(f"   Deadline: {tender.get('deadline', 'N/A')}")
                print(f"   Location: {tender.get('location', 'N/A')}")
                desc = tender.get('description', 'N/A')
                print(f"   Description: {desc[:200]}..." if len(desc) > 200 else f"   Description: {desc}")
                print(f"   Keywords: {', '.join(tender.get('keywords', []))}")
                print(f"   Relevance: {tender.get('relevance_score', 0):.2f}")
        else:
            print("\nâš ï¸ Aucun tender extrait")
            print("   VÃ©rifiez les logs pour voir les dÃ©tails de l'extraction")
        
        return tenders
        
    finally:
        Path(pdf_path).unlink(missing_ok=True)


def test_direct_extraction():
    """Test direct extraction (no RAG, full text to LLM) on real PDF."""
    
    print("\n" + "=" * 80)
    print("TEST 4: Extraction directe (sans RAG) - PDF rÃ©el")
    print("=" * 80)
    
    # Download PDF
    pdf_path = download_pdf(PDF_URL)
    
    try:
        print(f"\nğŸ“„ PDF: {pdf_path}")
        print("\nğŸ”„ Extraction directe en cours...")
        print("   (Texte complet envoyÃ© au LLM, pas de RAG)")
        print("   âš ï¸  Peut Ã©chouer si le PDF est trop grand pour le contexte LLM")
        
        # Run direct extraction (bypass RAG)
        tenders = parse_pdf_with_rag(
            pdf_path=pdf_path,
            source_name="DGCMEF_QUOTIDIEN_4269_DIRECT",
            filename="Quotidien NÂ°4269.pdf",
            metadata={"source": "dgcmef", "type": "quotidien"},
            use_llm=True,
            use_direct_extraction=True  # Skip RAG
        )
        
        print("\nâœ… Extraction terminÃ©e!")
        print(f"   Tenders extraits: {len(tenders)}")
        
        # Save to JSON file
        save_tenders_to_json(tenders, "direct_extraction")
        
        if tenders:
            print("\nğŸ“‹ RÃ©sultats:")
            for i, tender in enumerate(tenders[:5], 1):  # Show first 5
                print(f"\n   [{i}] {tender.get('reference', 'N/A')}")
                print(f"       EntitÃ©: {tender.get('entity', 'N/A')[:50]}...")
                print(f"       Budget: {tender.get('budget', 'N/A')}")
                print(f"       Deadline: {tender.get('deadline', 'N/A')}")
            if len(tenders) > 5:
                print(f"\n   ... et {len(tenders) - 5} autres tenders")
        else:
            print("\nâš ï¸ Aucun tender extrait")
        
        return tenders
        
    finally:
        Path(pdf_path).unlink(missing_ok=True)


if __name__ == "__main__":
    print("\nğŸ§ª Testing PDF RAG Extraction Pipeline\n")
    
    # Clear JSON file before starting
    clear_json_file()
    
    # Run all tests
    # print("1ï¸âƒ£ Test extraction de texte")
    # test_extract_text()
    
    # print("\n\n2ï¸âƒ£ Test dÃ©coupage en chunks")
    # test_chunk_splitting()
    
    # print("\n\n3ï¸âƒ£ Test extraction RAG complÃ¨te")
    # test_full_rag_extraction()
    
    print("\n\n4ï¸âƒ£ Test extraction directe")
    test_direct_extraction()
    
    print("\n\nâœ… Tous les tests terminÃ©s!")
    print(f"ğŸ“„ RÃ©sultats sauvegardÃ©s dans: {OUTPUT_JSON}")
    print("=" * 80)
